{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c1d58e-2406-4f1d-ba26-c1e747ee15ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-api-python-client\n",
    "# !pip install textblob\n",
    "# !pip install wordcloud matplotlib nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e153f-ff9e-48b5-aed3-6df63b26a1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build # For interacting with the YouTube API\n",
    "import re # For extracting video ID from a URL\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01987ea2-ce39-44c8-9913-a3395f37c671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Function: Extract Video ID from URL --------\n",
    "def extract_video_id(url):\n",
    "    \"\"\"\n",
    "    Extracts the 11-character YouTube video ID from a given URL.\n",
    "    Supports both 'watch?v=' and 'youtu.be' formats.\n",
    "    \"\"\"\n",
    "    pattern = r\"(?:v=|\\/)([0-9A-Za-z_-]{11})\"\n",
    "    match = re.search(pattern, url)\n",
    "    return match.group(1) if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506d0f91-f2ca-4c7a-a5e6-224f4a687fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Function: Fetch Comments Using YouTube Data API --------\n",
    "def get_comments(video_id, api_key, max_results=100):\n",
    "    \"\"\"\n",
    "    Fetches up to 'max_results' top-level comments for the given video ID\n",
    "    using the YouTube Data API v3.\n",
    "    \"\"\"\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "    comments = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while len(comments) < max_results:\n",
    "        response = youtube.commentThreads().list(\n",
    "            part='snippet',\n",
    "            videoId=video_id,\n",
    "            maxResults=min(100, max_results - len(comments)),\n",
    "            textFormat='plainText',\n",
    "            pageToken=next_page_token\n",
    "        ).execute()\n",
    "\n",
    "        # Extract comment text\n",
    "        for item in response['items']:\n",
    "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "            comments.append(comment)\n",
    "\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e474f822-291e-4605-8605-fa7c9f08e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Main Script --------\n",
    "# 🔑 Replace this with your actual YouTube Data API key\n",
    "API_KEY = \"API KEY HERE\"\n",
    "\n",
    "# Prompt the user to input a YouTube video link\n",
    "url = input(\"🔗 Enter the YouTube video URL: \")\n",
    "\n",
    "# Extract the video ID\n",
    "video_id = extract_video_id(url)\n",
    "\n",
    "if not video_id:\n",
    "    print(\"⛔ Could not extract a valid video ID from the URL.\")\n",
    "else:\n",
    "    print(\"📥 Fetching comments...\")\n",
    "    # Get up to 50 comments\n",
    "    comments = get_comments(video_id, API_KEY, max_results=50)\n",
    "\n",
    "    # Print the first 10 comments for confirmation\n",
    "    for i, comment in enumerate(comments[:60], 1):\n",
    "        print(f\"{i}. {comment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e43ac37-0cdf-4e08-9a98-aab551b73445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(comments):\n",
    "    \"\"\"\n",
    "    Analyze sentiment for each comment.\n",
    "    Returns a list of (comment, polarity, sentiment) tuples.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for comment in comments:\n",
    "        blob = TextBlob(comment)\n",
    "        polarity = blob.sentiment.polarity # from -1 (very negative) to +1 (very positive)\n",
    "\n",
    "        # Label the sentiment\n",
    "        if polarity > 0.1:\n",
    "            sentiment = \"positive\"\n",
    "        elif polarity < -0.1:\n",
    "            sentiment = \"negative\"\n",
    "        else:\n",
    "            sentiment = \"neutral\"\n",
    "\n",
    "        results.append((comment, polarity, sentiment))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f084f5-3936-41fb-b1db-e1e212dd041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_sentiment(results):\n",
    "    \"\"\"\n",
    "    Summarizes sentiment analysis results.\n",
    "    Prints number and percentage of each sentiment,\n",
    "    and gives a final overall sentiment conclusion.\n",
    "    \"\"\"\n",
    "    # Convert to DataFrame for easy counting\n",
    "    df = pd.DataFrame(results, columns=[\"Comment\", \"Polarity\", \"Sentiment\"])\n",
    "    total = len(df)\n",
    "\n",
    "    positive = (df[\"Sentiment\"] == \"positive\").sum()\n",
    "    negative = (df[\"Sentiment\"] == \"negative\").sum()\n",
    "    neutral = (df[\"Sentiment\"] == \"neutral\").sum()\n",
    "\n",
    "    print(\"\\n📊 Sentiment Summary:\")\n",
    "    print(f\"Total Comments: {total}\")\n",
    "    print(f\"✅ Positive: {positive} ({positive/total*100:.1f}%)\")\n",
    "    print(f\"❌ Negative: {negative} ({negative/total*100:.1f}%)\")\n",
    "    print(f\"⚪ Neutral : {neutral} ({neutral/total*100:.1f}%)\")\n",
    "\n",
    "    # Calculate average polarity\n",
    "    avg_polarity = df[\"Polarity\"].mean()\n",
    "    print(f\"\\n🧮 Average Polarity Score: {avg_polarity:.2f}\")\n",
    "\n",
    "    # Final decision\n",
    "    if avg_polarity > 0.1:\n",
    "        print(\"🟢 Overall Sentiment: Mostly Positive\")\n",
    "    elif avg_polarity < -0.1:\n",
    "        print(\"🔴 Overall Sentiment: Mostly Negative\")\n",
    "    else:\n",
    "        print(\"🟡 Overall Sentiment: Mostly Neutral\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b5ce1-9150-419b-a956-fa8ba9859ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyze_sentiment(comments) # Step 1: analyze\n",
    "df = summarize_sentiment(results) # Step 2: summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6bbb2-beca-483b-9b92-5e2adbf754b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wordcloud(comments, title=\"Word Cloud\"):\n",
    "    \"\"\"\n",
    "    Generate and display a word cloud from a list of comments,\n",
    "    removing common stopwords.\n",
    "    \"\"\"\n",
    "    # Combine all comments into one string\n",
    "    text = \" \".join(comments)\n",
    "\n",
    "    # Use built-in English stopwords + NLTK stopwords\n",
    "    custom_stopwords = set(STOPWORDS).union(set(stopwords.words('english')))\n",
    "\n",
    "    # Generate the word cloud\n",
    "    wordcloud = WordCloud(\n",
    "        width=800,\n",
    "        height=400,\n",
    "        background_color='white',\n",
    "        stopwords=custom_stopwords,\n",
    "        max_words=200,\n",
    "        collocations=False\n",
    "    ).generate(text)\n",
    "\n",
    "    # Display the image\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title, fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60e6150-bab8-48b5-8cc1-4a5d10ffe5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_comments_by_sentiment(results):\n",
    "    \"\"\"\n",
    "    Splits comments into positive, negative, and neutral based on sentiment label.\n",
    "    \"\"\"\n",
    "    positive_comments = [comment for comment, _, sentiment in results if sentiment == \"positive\"]\n",
    "    negative_comments = [comment for comment, _, sentiment in results if sentiment == \"negative\"]\n",
    "    neutral_comments = [comment for comment, _, sentiment in results if sentiment == \"neutral\"]\n",
    "    return positive_comments, negative_comments, neutral_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a88547-f759-4db3-a4ea-838cc57e1cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split comments\n",
    "positive_comments, negative_comments, neutral_comments = split_comments_by_sentiment(results)\n",
    "\n",
    "# 2. Generate word clouds\n",
    "generate_wordcloud(positive_comments, title=\" Word Cloud - Positive Comments\")\n",
    "generate_wordcloud(negative_comments, title=\" Word Cloud - Negative Comments\")\n",
    "generate_wordcloud(neutral_comments, title=\" Word Cloud - Neutral Comments\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
